{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf093e70",
   "metadata": {},
   "source": [
    "# CloudSeg: Training & Visualization\n",
    "\n",
    "This notebook will train your `SimpleSegModel` on the SWINySEG data and visualize:\n",
    "\n",
    "- A sample image & mask\n",
    "- Training vs. validation loss curves\n",
    "- IoU metric per epoch\n",
    "- A metrics table and its correlation matrix\n",
    "- Side-by-side sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985bd78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.data_loader import get_simple_loaders\n",
    "from src.model import SimpleSegModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8391db6a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 4\n",
    "IMG_SIZE   = (256, 256)\n",
    "LR         = 1e-3\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "# Create loaders (train & val)\n",
    "train_loader = get_simple_loaders(\n",
    "    images_dir=\"data/raw/images\",\n",
    "    masks_dir=\"data/raw/masks\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    img_size=IMG_SIZE,\n",
    "    normalize=True,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = get_simple_loaders(\n",
    "    images_dir=\"data/raw/images\",\n",
    "    masks_dir=\"data/raw/masks\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    img_size=IMG_SIZE,\n",
    "    normalize=True,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f051e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "imgs, masks = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(8,4))\n",
    "axes[0].imshow(imgs[0].permute(1,2,0))\n",
    "axes[0].set_title(\"Input Image\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(masks[0,0], cmap=\"gray\")\n",
    "axes[1].set_title(\"Mask\")\n",
    "axes[1].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c50c1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Running on:\", device)\n",
    "\n",
    "model     = SimpleSegModel().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Early‐stop settings\n",
    "MAX_EPOCHS        = 50\n",
    "PATIENCE          = 5\n",
    "best_val_loss     = float(\"inf\")\n",
    "epochs_no_improve = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses   = []\n",
    "val_ious     = []\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS+1):\n",
    "    # ── Training ──\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for imgs, masks in train_loader:\n",
    "        imgs, masks = imgs.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss    = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "    train_loss = running_train_loss / len(train_loader)\n",
    "    \n",
    "    # ── Validation ──\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    intersection, union = 0.0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in val_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            running_val_loss += criterion(outputs, masks).item()\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            intersection += (preds * masks).sum().item()\n",
    "            union        += (preds + masks).sum().item() - (preds * masks).sum().item()\n",
    "    val_loss = running_val_loss / len(val_loader)\n",
    "    val_iou  = (intersection + 1e-6) / (union + 1e-6)\n",
    "    \n",
    "    # ── Early stopping check ──\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss     = val_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"No improvement in {PATIENCE} epochs—stopping at epoch {epoch}.\")\n",
    "            break\n",
    "\n",
    "    # ── Record & print ──\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_ious.append(val_iou)\n",
    "    print(f\"Epoch {epoch}/{MAX_EPOCHS} — \"\n",
    "          f\"train_loss: {train_loss:.4f}, \"\n",
    "          f\"val_loss: {val_loss:.4f}, \"\n",
    "          f\"val_iou: {val_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f1201",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(1, MAX_EPOCHS+1), train_losses, label=\"Train\")\n",
    "plt.plot(range(1, MAX_EPOCHS+1), val_losses,   label=\"Validation\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65a53f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    \"epoch\":       list(range(1, MAX_EPOCHS+1)),\n",
    "    \"train_loss\":  train_losses,\n",
    "    \"val_loss\":    val_losses,\n",
    "    \"val_iou\":     val_ious\n",
    "}).set_index(\"epoch\")\n",
    "\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068b211",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "corr = metrics_df.corr()\n",
    "plt.figure()\n",
    "plt.imshow(corr, interpolation=\"nearest\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.xticks(range(len(corr)), corr.columns)\n",
    "plt.yticks(range(len(corr)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cfedb0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Grab a few from the val set\n",
    "imgs, masks = next(iter(val_loader))\n",
    "outputs     = model(imgs.to(device)).cpu()\n",
    "preds       = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "for i in range(3):\n",
    "    fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "    axes[0].imshow(imgs[i].permute(1,2,0)); axes[0].set_title(\"Image\"); axes[0].axis(\"off\")\n",
    "    axes[1].imshow(masks[i,0], cmap=\"gray\");        axes[1].set_title(\"Mask\");  axes[1].axis(\"off\")\n",
    "    axes[2].imshow(preds[i,0], cmap=\"gray\");        axes[2].set_title(\"Pred\");  axes[2].axis(\"off\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
